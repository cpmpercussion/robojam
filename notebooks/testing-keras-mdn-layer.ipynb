{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Input, merge\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "from tensorflow.contrib.distributions import Categorical, Mixture, MultivariateNormalDiag\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureDensity(Layer):\n",
    "    def __init__(self, output_dim, num_mix, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.num_mix = num_mix\n",
    "        with tf.name_scope('MDNLayer'):\n",
    "            self.mdn_mus     = Dense(self.num_mix * self.output_dim, name='mdn_mus') # mix*output vals, no activation\n",
    "            self.mdn_sigmas  = Dense(self.num_mix * self.output_dim, activation=K.exp, name='mdn_sigmas') # mix*output vals exp activation\n",
    "            self.mdn_pi      = Dense(self.num_mix, activation=K.softmax, name='mdn_pi') # mix vals, softmax\n",
    "        super(MixtureDensity, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mdn_mus.build(input_shape)\n",
    "        self.mdn_sigmas.build(input_shape)\n",
    "        self.mdn_pi.build(input_shape)\n",
    "        self.trainable_weights = self.mdn_mus.trainable_weights + self.mdn_sigmas.trainable_weights + self.mdn_pi.trainable_weights\n",
    "        self.non_trainable_weights = self.mdn_mus.non_trainable_weights + self.mdn_sigmas.non_trainable_weights + self.mdn_pi.non_trainable_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        m = self.mdn_mus(x)\n",
    "        s = self.mdn_sigmas(x)\n",
    "        p = self.mdn_pi(x)\n",
    "        \n",
    "        with tf.name_scope('MDNLayer'):\n",
    "            mdn_out = keras.layers.concatenate([m, s, p], name='mdn_out')\n",
    "        return mdn_out\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'output_dim': self.output_dim,                                    \n",
    "                  'num_mix': self.num_mix}\n",
    "        base_config = super(MDN, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def get_loss_func(self):\n",
    "        def unigaussian_loss(y_true, y_pred):\n",
    "            mix = tf.range(start = 0, limit = self.num_mix)            \n",
    "            out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[self.num_mix * self.output_dim, self.num_mix, self.num_mix], axis=1, name='mdn_coef_split')\n",
    "            \n",
    "            def loss_i(i):         \n",
    "                batch_size = tf.shape(out_sigma)[0]\n",
    "                sigma_i = tf.slice(out_sigma, [0, i], [batch_size, 1], name='mdn_sigma_slice')\n",
    "                pi_i = tf.slice(out_pi, [0, i], [batch_size, 1], name='mdn_pi_slice')        \n",
    "                mu_i = tf.slice(out_mu, [0, i * self.output_dim], [batch_size, self.output_dim], name='mdn_mu_slice')\n",
    "                dist = tf.distributions.Normal(loc=mu_i, scale=sigma_i)\n",
    "                loss = dist.prob(y_true)\n",
    "                loss = pi_i * loss\n",
    "                return loss\n",
    "\n",
    "            result = tf.map_fn(lambda  m: loss_i(m), mix, dtype=tf.float32, name='mix_map_fn')\n",
    "            \n",
    "            result = tf.reduce_sum(result, axis=0, keepdims=False)\n",
    "            result = -tf.log(result)\n",
    "            result = tf.reduce_mean(result)\n",
    "            return result\n",
    "\n",
    "        with tf.name_scope('MDNLayer'):\n",
    "            return unigaussian_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mixture_loss_func(output_dim, num_mixes):\n",
    "    \"\"\"Construct a loss functions for the MDN layer parametrised by number of mixtures.\"\"\"\n",
    "    \n",
    "    # Construct a loss function with the right number of mixtures and outputs\n",
    "    def loss_func(y_true, y_pred):\n",
    "        out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[num_mixes * output_dim, \n",
    "                                                                         num_mixes * output_dim, \n",
    "                                                                         num_mixes], \n",
    "                                             axis=1, name='mdn_coef_split')\n",
    "        cat = Categorical(logits=out_pi)\n",
    "        component_splits = [output_dim] * num_mixes\n",
    "        mus = tf.split(out_mu, num_or_size_splits=component_splits, axis=1)\n",
    "        sigs = tf.split(out_sigma, num_or_size_splits=component_splits, axis=1)\n",
    "        coll = [MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale\n",
    "            in zip(mus, sigs)]\n",
    "        mixture = Mixture(cat=cat, components=coll)\n",
    "        loss = mixture.log_prob(y_true)\n",
    "        loss = tf.negative(loss)\n",
    "        #         loss = reduce_mean(loss)\n",
    "        print(\"y_pred:\", y_pred.shape)\n",
    "        print(\"mu:\",  out_mu.shape)\n",
    "        print(\"sigma:\", out_sigma.shape)\n",
    "        print(\"pi:\", out_pi.shape)\n",
    "        print(\"splits:\", component_splits)\n",
    "        print(\"Mix:\", mixture)\n",
    "        return loss\n",
    "    \n",
    "    # Actually return the loss_func\n",
    "    with tf.name_scope('MDNLayer'):\n",
    "        return loss_func\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: (?, 35)\n",
      "mu: (?, 15)\n",
      "sigma: (?, 15)\n",
      "pi: (?, 5)\n",
      "splits: [3, 3, 3, 3, 3]\n",
      "Mix: tf.distributions.Mixture(\"Mixture\", batch_shape=(?,), event_shape=(3,), dtype=float32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 10, 64)            17408     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "mixture_density_6 (MixtureDe (None, 3)                 2275      \n",
      "=================================================================\n",
      "Total params: 52,707\n",
      "Trainable params: 52,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIMENSION = 3\n",
    "NUMBER_MIXTURES = 5\n",
    "LSTM_SIZE = 64\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(LSTM_SIZE, batch_input_shape=(None,10,OUTPUT_DIMENSION), return_sequences=True))\n",
    "model.add(keras.layers.LSTM(LSTM_SIZE))\n",
    "model.add(MixtureDensity(OUTPUT_DIMENSION, NUMBER_MIXTURES))\n",
    "model.compile(loss=get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer=keras.optimizers.Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 10, 64)            17408     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "mixture_density_4 (MixtureDe (None, 3)                 2275      \n",
      "=================================================================\n",
      "Total params: 52,707\n",
      "Trainable params: 52,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "y_pred: (?, 35)\n",
      "mu: (?, 15)\n",
      "sigma: (?, 15)\n",
      "pi: (?, 5)\n",
      "splits: [3, 3, 3, 3, 3]\n",
      "Mix: tf.distributions.Mixture(\"Mixture\", batch_shape=(?,), event_shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Testing creation of a mixture model loss function.\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(64, batch_input_shape=(None,10,3), return_sequences=True))\n",
    "model.add(keras.layers.LSTM(64))\n",
    "m = MixtureDensity(3, 5)\n",
    "model.add(m)\n",
    "# model.compile(loss=m.get_loss_func(), optimizer=keras.optimizers.Adam())\n",
    "model.summary()\n",
    "\n",
    "num_mixes = 5\n",
    "output_dim = 3\n",
    "y_pred = model.output\n",
    "# Start messing around with model.output.\n",
    "out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[num_mixes * output_dim, num_mixes * output_dim, num_mixes], axis=1, name='mdn_coef_split')\n",
    "cat = Categorical(logits=out_pi)\n",
    "component_splits = [output_dim] * num_mixes\n",
    "mus = tf.split(out_mu, num_or_size_splits=component_splits, axis=1)\n",
    "sigs = tf.split(out_sigma, num_or_size_splits=component_splits, axis=1)\n",
    "coll = [MultivariateNormalDiag(loc=loc, scale_diag=scale) for loc, scale\n",
    "    in zip(mus, sigs)]\n",
    "mixture = Mixture(cat=cat, components=coll)\n",
    "\n",
    "print(\"y_pred:\", y_pred.shape)\n",
    "print(\"mu:\",  out_mu.shape)\n",
    "print(\"sigma:\", out_sigma.shape)\n",
    "print(\"pi:\", out_pi.shape)\n",
    "print(\"splits:\", component_splits)\n",
    "print(\"Mix:\", mixture)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MultivariateNormalDiag(loc=out_mu, scale_diag=out_sigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
