{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Input, merge\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "from tensorflow.contrib.distributions import Categorical, Mixture, MultivariateNormalDiag\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureDensity(Layer):\n",
    "    def __init__(self, output_dim, num_mix, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.num_mix = num_mix\n",
    "        with tf.name_scope('MDNLayer'):\n",
    "            self.mdn_mus     = Dense(self.num_mix * self.output_dim, name='mdn_mus') # no activation\n",
    "            self.mdn_sigmas  = Dense(self.num_mix, activation=K.exp, name='mdn_sigmas') # no activation \n",
    "            self.mdn_pi      = Dense(self.num_mix, activation=K.softmax, name='mdn_pi') # no activation\n",
    "        super(MixtureDensity, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mdn_mus.build(input_shape)\n",
    "        self.mdn_sigmas.build(input_shape)\n",
    "        self.mdn_pi.build(input_shape)\n",
    "        self.trainable_weights = self.mdn_mus.trainable_weights + self.mdn_sigmas.trainable_weights + self.mdn_pi.trainable_weights\n",
    "        self.non_trainable_weights = self.mdn_mus.non_trainable_weights + self.mdn_sigmas.non_trainable_weights + self.mdn_pi.non_trainable_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        m = self.mdn_mus(x)\n",
    "        s = self.mdn_sigmas(x)\n",
    "        p = self.mdn_pi(x)\n",
    "        \n",
    "        with tf.name_scope('MDNLayer'):\n",
    "            mdn_out = keras.layers.concatenate([m, s, p], name='mdn_out')\n",
    "        return mdn_out\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'output_dim': self.output_dim,                                    \n",
    "                  'num_mix': self.num_mix}\n",
    "        base_config = super(MDN, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def get_loss_func(self):\n",
    "        def multivariate_loss(y_true, y_pred):\n",
    "            mix = tf.range(start = 0, limit = self.num_mix)            \n",
    "            out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[self.num_mix * self.output_dim, self.num_mix, self.num_mix], axis=1, name='mdn_coef_split')\n",
    "                tf.distributions.MultivariateNormalDiag\n",
    "\n",
    "        def unigaussian_loss(y_true, y_pred):\n",
    "            mix = tf.range(start = 0, limit = self.num_mix)            \n",
    "            out_mu, out_sigma, out_pi = tf.split(y_pred, num_or_size_splits=[self.num_mix * self.output_dim, self.num_mix, self.num_mix], axis=1, name='mdn_coef_split')\n",
    "            \n",
    "            def loss_i(i):         \n",
    "                batch_size = tf.shape(out_sigma)[0]\n",
    "                sigma_i = tf.slice(out_sigma, [0, i], [batch_size, 1], name='mdn_sigma_slice')\n",
    "                pi_i = tf.slice(out_pi, [0, i], [batch_size, 1], name='mdn_pi_slice')        \n",
    "                mu_i = tf.slice(out_mu, [0, i * self.output_dim], [batch_size, self.output_dim], name='mdn_mu_slice')\n",
    "                dist = tf.distributions.Normal(loc=mu_i, scale=sigma_i)\n",
    "                loss = dist.prob(y_true)\n",
    "                loss = pi_i * loss\n",
    "                return loss\n",
    "\n",
    "            result = tf.map_fn(lambda  m: loss_i(m), mix, dtype=tf.float32, name='mix_map_fn')\n",
    "            \n",
    "            result = tf.reduce_sum(result, axis=0, keepdims=False)\n",
    "            result = -tf.log(result)\n",
    "            result = tf.reduce_mean(result)\n",
    "            return result\n",
    "        \n",
    "\n",
    "        with tf.name_scope('MDNLayer'):\n",
    "            return unigaussian_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.distributions import Categorical, Mixture, MultivariateNormalDiag\n",
    "\n",
    "def get_mixture_loss_func(num_mixes, output_dim):\n",
    "    \"\"\"Construct a loss functions for the MDN layer parametrised by number of mixtures.\"\"\"\n",
    "    def loss_func(y_true, y_pred):\n",
    "        mix = tf.range(start = 0, limit = self.num_mix)\n",
    "        mus, sigmas, pis = tf.split(value=y_pred, num_or_size_splits=[num_mixes * output_dim, num_mixes, num_mixes], axis=1, name=\"mixture_split\")\n",
    "        cat = Categorical(logits=pis)\n",
    "        locs = \n",
    "        \n",
    "    with tf.name_scope('MDNLayer'):\n",
    "        return loss_func\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_25 (LSTM)               (None, 10, 64)            17408     \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "mixture_density_12 (MixtureD (None, 3)                 1625      \n",
      "=================================================================\n",
      "Total params: 52,057\n",
      "Trainable params: 52,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(64, batch_input_shape=(None,10,3), return_sequences=True))\n",
    "model.add(keras.layers.LSTM(64))\n",
    "m = MixtureDensity(3, 5)\n",
    "model.add(m)\n",
    "model.compile(loss=m.get_loss_func(), optimizer=keras.optimizers.Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
