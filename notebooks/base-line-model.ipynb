{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base-line predictor\n",
    "\n",
    "Predicts the next value is equal to the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import absolute_import\n",
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "import keras\n",
    "# little path hack to get robojam from one directory up in the filesystem.\n",
    "from context import * # imports robojam\n",
    "# import robojam # alternatively do this.\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "input_colour = 'darkblue'\n",
    "gen_colour = 'firebrick'\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_df_to_array(perf_df):\n",
    "    \"\"\"Converts a dataframe of a performance into array a,b,dt format.\"\"\"\n",
    "    perf_df['dt'] = perf_df.time.diff()\n",
    "    perf_df.dt = perf_df.dt.fillna(0.0)\n",
    "    # Clean performance data\n",
    "    # Tiny Performance bounds defined to be in [[0,1],[0,1]], edit to fix this.\n",
    "    perf_df.set_value(perf_df[perf_df.dt > 5].index, 'dt', 5.0)\n",
    "    perf_df.set_value(perf_df[perf_df.dt < 0].index, 'dt', 0.0)\n",
    "    perf_df.set_value(perf_df[perf_df.x > 1].index, 'x', 1.0)\n",
    "    perf_df.set_value(perf_df[perf_df.x < 0].index, 'x', 0.0)\n",
    "    perf_df.set_value(perf_df[perf_df.y > 1].index, 'y', 1.0)\n",
    "    perf_df.set_value(perf_df[perf_df.y < 0].index, 'y', 0.0)\n",
    "    return np.array(perf_df[['x', 'y', 'dt']])\n",
    "\n",
    "\n",
    "def perf_array_to_df(perf_array):\n",
    "    \"\"\"Converts an array of a performance (a,b,dt format) into a dataframe.\"\"\"\n",
    "    perf_array = perf_array.T\n",
    "    perf_df = pd.DataFrame({'x': perf_array[0], 'y': perf_array[1], 'dt': perf_array[2]})\n",
    "    perf_df['time'] = perf_df.dt.cumsum()\n",
    "    perf_df['z'] = 38.0\n",
    "    # As a rule of thumb, could classify taps with dt>0.1 as taps, dt<0.1 as moving touches.\n",
    "    perf_df['moving'] = 1\n",
    "    perf_df.set_value(perf_df[perf_df.dt > 0.1].index, 'moving', 0)\n",
    "    perf_df = perf_df.set_index(['time'])\n",
    "    return perf_df[['x', 'y', 'z', 'moving']]\n",
    "\n",
    "\n",
    "def random_touch():\n",
    "    \"\"\"Generate a random tiny performance touch.\"\"\"\n",
    "    return np.array([np.random.rand(), np.random.rand(), 0.01])\n",
    "\n",
    "\n",
    "def constrain_touch(touch):\n",
    "    \"\"\"Constrain touch values from the MDRNN\"\"\"\n",
    "    touch[0] = min(max(touch[0], 0.0), 1.0)  # x in [0,1]\n",
    "    touch[1] = min(max(touch[1], 0.0), 1.0)  # y in [0,1]\n",
    "    touch[2] = max(touch[2], 0.001)  # dt # define minimum time step\n",
    "    return touch\n",
    "\n",
    "def generate_random_tiny_performance(model, first_touch, time_limit=5.0, steps_limit=1000, temp=1.0, model_file=None):\n",
    "    \"\"\"Generates a tiny performance up to 5 seconds in length.\"\"\"\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    previous_touch = first_touch\n",
    "    performance = [previous_touch.reshape((3,))]\n",
    "    while (steps < steps_limit and time < time_limit):\n",
    "        previous_touch = model.predict(previous_touch.reshape(1,1,3))\n",
    "        output_touch = previous_touch.reshape(3,)\n",
    "        output_touch = constrain_touch(output_touch)\n",
    "        performance.append(output_touch.reshape((3,)))\n",
    "        steps += 1\n",
    "        time += output_touch[2]\n",
    "    return np.array(performance)\n",
    "\n",
    "\n",
    "def condition_and_generate(model, perf, time_limit=5.0, steps_limit=1000, temp=1.0, model_file=None):\n",
    "    \"\"\"Conditions the network on an existing tiny performance, then generates a new one.\"\"\"\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    # condition\n",
    "    for touch in perf:\n",
    "        previous_touch = model.predict(touch.reshape(1,1,3))\n",
    "    output = [previous_touch.reshape((3,))]\n",
    "    while (steps < steps_limit and time < time_limit):\n",
    "        previous_touch = model.predict(previous_touch.reshape(1,1,3))\n",
    "        output_touch = previous_touch.reshape(3,)\n",
    "        output_touch = constrain_touch(output_touch)\n",
    "        output.append(output_touch.reshape((3,)))\n",
    "        steps += 1\n",
    "        time += output_touch[2]\n",
    "    net_output = np.array(output)\n",
    "    return net_output\n",
    "\n",
    "def divide_performance_into_swipes(perf_df):\n",
    "    \"\"\"Divides a performance into a sequence of swipe dataframes for plotting.\"\"\"\n",
    "    touch_starts = perf_df[perf_df.moving == 0].index\n",
    "    performance_swipes = []\n",
    "    remainder = perf_df\n",
    "    for att in touch_starts:\n",
    "        swipe = remainder.iloc[remainder.index < att]\n",
    "        performance_swipes.append(swipe)\n",
    "        remainder = remainder.iloc[remainder.index >= att]\n",
    "    performance_swipes.append(remainder)\n",
    "    return performance_swipes\n",
    "\n",
    "def plot_2D(perf_df, name=\"foo\", saving=False):\n",
    "    \"\"\"Plot a 2D representation of a performance 2D\"\"\"\n",
    "    swipes = divide_performance_into_swipes(perf_df)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=gen_colour, linewidth=5.0)\n",
    "    plt.ylim(1.0,0)\n",
    "    plt.xlim(0,1.0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if saving:\n",
    "        plt.savefig(name+\".png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "def plot_double_2d(perf1, perf2, name=\"foo\", saving=False):\n",
    "    \"\"\"Plot two performances in 2D\"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    swipes = divide_performance_into_swipes(perf1)\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=input_colour, linewidth=5.0)\n",
    "    swipes = divide_performance_into_swipes(perf2)\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=gen_colour, linewidth=5.0)\n",
    "    plt.ylim(1.0,0)\n",
    "    plt.xlim(0,1.0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if saving:\n",
    "        plt.savefig(name+\".png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base line model is not trained\n",
    "\n",
    "# Training Hyperparameters:\n",
    "SEQ_LEN = 1\n",
    "BATCH_SIZE = 1\n",
    "#HIDDEN_UNITS = 64\n",
    "#EPOCHS = 100\n",
    "#VAL_SPLIT=0.2\n",
    "\n",
    "# These settings train for 2.1 epochs which is pretty good!\n",
    "SEED = 2345  # 2345 seems to be good.\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "# tf.set_random_seed(5791)  # only works for current graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total non-overlapping examples: 2149209\n",
      "Done initialising loader.\n",
      "X: (2149209, 1, 3) y: (2149209, 3)\n"
     ]
    }
   ],
   "source": [
    "microjam_data_file_name = \"../datasets/TinyPerformanceCorpus.h5\"\n",
    "metatone_data_file_name = \"../datasets/MetatoneTinyPerformanceRecords.h5\"\n",
    "\n",
    "with h5py.File(microjam_data_file_name, 'r') as data_file:\n",
    "    microjam_corpus = data_file['total_performances'][:]\n",
    "with h5py.File(metatone_data_file_name, 'r') as data_file:\n",
    "    metatone_corpus = data_file['total_performances'][:]\n",
    "\n",
    "# sequence_loader = robojam.sample_data.SequenceDataLoader(num_steps=SEQ_LEN + 1, batch_size=BATCH_SIZE, corpus=microjam_corpus, overlap=False)\n",
    "sequence_loader = robojam.sample_data.SequenceDataLoader(num_steps=SEQ_LEN + 1, batch_size=BATCH_SIZE, corpus=metatone_corpus, overlap=False)\n",
    "\n",
    "X, y = sequence_loader.seq_to_singleton_format()\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"X:\", X.shape, \"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_line_predictor(x):\n",
    "    return x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (1, 3)                    0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = keras.Sequential()\n",
    "decoder.add(keras.layers.Lambda(base_line_predictor, batch_input_shape=(None,1,3)))#((lambda x: x),batch_input_shape=(1,1,3)))\n",
    "decoder.compile(loss='mse', optimizer=keras.optimizers.Adam())\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2149209/2149209 [==============================] - 13s 6us/step\n",
      "0.0628041825509\n"
     ]
    }
   ],
   "source": [
    "# Makes no sense to train the base-line preditor (no weights), instead we only evaluate.\n",
    "#history = decoder.fit(X, y, epoch=10)\n",
    "\n",
    "loss = decoder.evaluate(X,y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "#training_loss = history.history['loss']\n",
    "#test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "#epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# # Visualize loss history\n",
    "# plt.plot(epoch_count, training_loss, 'r--')\n",
    "# plt.plot(epoch_count, test_loss, 'b-')\n",
    "# plt.legend(['Training Loss', 'Test Loss'])\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1264ca320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = generate_random_tiny_performance(decoder, random_touch()) #, time_limit=60.0, steps_limit=10000) \n",
    "plot_2D(perf_array_to_df(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125436748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = random.randint(0,len(sequence_loader.examples))\n",
    "\n",
    "p = condition_and_generate(decoder,sequence_loader.examples[t])\n",
    "plot_double_2d(perf_array_to_df(sequence_loader.examples[t]), perf_array_to_df(p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
